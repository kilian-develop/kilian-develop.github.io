---
title: 캐싱 전략? 어떻게 사용해야 적절할까?
categories: Cache
layout: post
tags:
  - Spring
  - Cache
date: 2025-11-24
excerpt: 캐싱 전략에 따라 어떻게 사용하는 것이 좋을지 고민해봅니다.
image_thumbnail: /assets/images/posts/redis.png
---
# 캐시
---
**캐시**라고 하면 흔하게 어떤 데이터를 매번 직접 요청하여 가져오는 것이 아니라 공부할 때 벽에 붙여놓는 포스트잇 처럼 빈번하게 찾아야하는 정보를 찾기 빠른 곳에 저장해두고 조회하는 방식을 의미합니다.

하지만 인터넷에는 여러 캐시 전략들이 존재하는 걸 보고,
**"단순히 빠르게 조회하기 위한 방식이면 다양할 이유가 없지 않을까?"** 라는 생각이 들었습니다.

그렇다면 다양한 전략이 존재하는 이유는 뭘까요?

아마도 **"모든 데이터가 같은 특성을 가지지 않기 때문"**이 아닐까 생각했습니다.

어떤 데이터는 자주 조회되지만, 어떤 데이터는 자주 변경됩니다. 또 어떤 데이터는 실시간성이 중요하고, 어떤 데이터는 그렇지 않습니다.

그래서 저는 캐시 전략들을 살펴보고 이커머스 도메인에서 **각 전략이 어떤 데이터 특성에 맞는지** 고민해봤습니다.

# Cache Aside
---
**Cache Aside** 전략은 데이터가 요청되면 캐시를 먼저 읽고 캐시에 데이터가 없으면 데이터베이스에서 검색하여 조회한 후에 다음에 조회 시 캐시에서 조회할 수 있도록 캐시에 저장합니다.

![[image.png]]

이 전략의 핵심은 **"자주 조회되는 데이터를 특정할 수 있는가"**입니다.

만약 조회 패턴이 명확하다면(예: 인기 상품 1000개가 전체 트래픽의 80%를 차지), Cache Aside는 매우 효과적입니다.

일례로 이커머스 도메인의 **상품 상세 조회**는 좋은 예시입니다.
인기 있는 상품들은 비인기 상품보다 훨씬 자주 조회되기 때문입니다.

실제로 이것이 얼마나 효과적인지 직접 테스트를 진행해봤습니다.

## Cache Aside 테스트
아래는 기존의 상품 상세 조회의 코드입니다.
```java
public ProductDetail getProductDetail(GetProductDetailQuery query) {  
    ProductId productId = new ProductId(query.getProductId());  
                Product product = productRepository.getById(productId);  
  
    Brand brand = brandRepository.getBrandById(product.getBrandId());  
    return new ProductDetail(product, brand);  
}
```
단순히 상품의 ID로 상품을 조회하고, 상품의 브랜드 ID로 브랜드 정보를 조회해 상세 정보(ProductDetail)를 반환합니다.

이 코드를 캐시를 적용하여 아래와 같이 구현했습니다.
```java
public ProductDetail getProductDetail(GetProductDetailQuery query) {  
    ProductId productId = new ProductId(query.getProductId());  
    return cacheRepository.findDetailBy(productId)  
            .orElseGet(() -> {  
                Product product = productRepository.getById(productId);  
                Brand brand = brandRepository.getBrandById(product.getBrandId());  
                ProductDetail productDetail = new ProductDetail(product, brand);  
                cacheRepository.save(productDetail);  
  
                return productDetail;  
            });  
}
```
`cacheRepository`를 통해 상품 상세 정보를 조회한 후 존재하지 않는 경우 데이터베이스에서 조회, 캐시를 저장합니다.

이제 **k6**를 통해 부하테스트를 진행해봅시다.

테스트 환경을 설정할 때 매우 중요한 결정을 했는데, 바로 **테스트 가정 설정**입니다.

- **전체 상품**: 100만 건
- **자주 조회되는 상품**: 1000개 (상품의 0.1%)
- **테스트 방식**: 이 1000개만 반복적으로 조회

왜 이렇게 설정했을까요?

실무에서 이커머스 서비스를 운영하면, 모든 상품이 동등하게 조회되지 않습니다.
인기 상품은 매일 수천 번 조회되지만, 니치한 상품은 일주일에 몇 번 조회되지 않을 수 있습니다.
이 비율이 Cache Aside 전략의 성공을 결정합니다.

테스트 스크립트는 다음과 같습니다.
```js
import http from 'k6/http';  
import {check, group} from 'k6';  
  
export const options = {  
    stages: [  
        {duration: '10s', target: 1000},   // 1000명까지 10초에 증가  
        {duration: '30s', target: 1000},   // 1000명 유지 30초  
        {duration: '10s', target: 0},    // 10초에 감소  
    ],  
    thresholds: {  
        http_req_duration: ['p(95)<500', 'p(99)<1000'],  
        http_req_failed: ['rate<0.1'],  
    },  
};  
  
const BASE_URL = 'http://localhost:8080';  
  
export default function () {  
    group('기본 상품 상세 조회', () => {  
        const randomId = Math.floor(Math.random() * 1001);  
        const response = http.get(`${BASE_URL}/api/v1/products/${randomId}/detail`);  
        check(response, {  
            'status는 200': (r) => r.status === 200,  
            '응답 시간 < 500ms': (r) => r.timings.duration < 500,  
        });  
    });  
}
```

0~10초간 VUs를  1000명까지 증가 시킨 후 30초간 1000VUs를 유지하고 남은 10초동안 VUs를 감소합니다.
봐야할 부분은 `randomId`값입니다. 랜덤한 1000개의 상품을 조회합니다. 
이 말인 즉, 자주 조회되는 상품을 1000개 정도로 지정하겠다는 의미입니다.

## 테스트 결과
### 캐시 적용 전
```
    HTTP
    http_req_duration..............: avg=1.83s min=4.51ms med=1.75s max=4.25s p(90)=3.25s p(95)=3.36s
      { expected_response:true }...: avg=1.83s min=4.51ms med=1.75s max=4.25s p(90)=3.25s p(95)=3.36s
    http_req_failed................: 0.07%  17 out of 22396
    http_reqs......................: 22396  447.896512/s
```

### 캐시 적용 후
```
    HTTP
    http_req_duration..............: avg=46.31ms min=264µs    med=46.05ms max=2.99s p(90)=71.51ms p(95)=81.25ms
      { expected_response:true }...: avg=46.26ms min=264µs    med=46.04ms max=2.99s p(90)=71.46ms p(95)=81.18ms
    http_req_failed................: 0.09%  803 out of 821803
    http_reqs......................: 821803 16435.660942/s
```

## 결과 분석

테스트 결과를 비교해보겠습니다.

| 지표 | 캐시 적용 전 | 캐시 적용 후 | 개선율 |
|------|-----------|-----------|--------|
| **평균 응답시간** | 1.83s | 46.31ms | **약 40배** |
| **최소 응답시간** | 4.51ms | 264µs | **약 17배** |
| **P(90)** | 3.25s | 71.51ms | **약 45배** |
| **P(95)** | 3.36s | 81.25ms | **약 41배** |
| **초당 처리량** | 447.9/s | 16,435.7/s | **약 37배** |

캐시 적용 후 **평균 응답 시간이 1.83초에서 46.31ms로 약 40배 개선**되었습니다.

특히 주목할 점은 **초당 처리량이 약 37배 증가**했다는 것입니다.
동시 사용자가 1000명으로 유지되는 상황에서, 기존에는 초당 447개의 요청만 처리했지만, 캐시 적용 후에는 초당 16,435개의 요청을 처리할 수 있게 되었습니다.


# Write-Behind
---
**Write Behind** 전략은 데이터를 요청 시 캐시에만 저장을하고 배치작업을 통해 주기적으로 데이터베이스로 옮기는 전략입니다.
![[image-2.png]]
이 패턴이 빛나는 경우는 언제일까요?

Cache Aside와는 다르게, Write-Behind는 **데이터 특성**이 다릅니다.

- **자주 변경되는 데이터**: 매번 데이터베이스에 쓰면 부하가 심함
- **실시간성이 낮은 데이터**: 실시간으로 업데이트된 데이터를 조회할 필요가 없음

e-commerce에서 이런 특성을 가진 데이터는 뭘까요?

**상품의 좋아요 기능**이 좋은 예입니다.

- **빈번함**: 수만 명의 사용자가 초 단위로 좋아요를 누릅니다 (물론 서비스의 규모마다 다를 수 있습니다.)
- **비즈니스 영향**: 좋아요 수가 실시간으로 정확할 필요는 없습니다
- **데이터베이스 부하**: 매번 쓰기 작업을 하면 DB 부하가 상당합니다

따라서 Write-Behind 전략은 **이런 데이터 특성에 매우 적합**하다고 생각했습니다.

아래 코드는 데이터베이스를 통해 좋아요를 구현한 코드입니다.
```java
@Transactional  
public void like(ProductLikeCommand command) {  
    User user = userRepository.getByIdentifier(new UserIdentifier(command.getUserIdentifier()));  
    Product product = productRepository.getByIdWithLock(new ProductId(command.getProductId()));  
  
    boolean isAlreadyLiked = productLikeRepository.findByUserIdAndProductIdWithLock(user.getId(), product.getId())  
            .isPresent();  
  
    if (!isAlreadyLiked) {  
        productLikeRepository.save(ProductLike.create(user.getId(), product.getId()));  
        productRepository.save(product.increaseLikeCount());  
    }  
}
```

Redis를 사용한다면, 어떤 자료구조가 적합할까요?

**고민 포인트**:
- 하나의 상품에 여러 사용자가 좋아요를 누름
- 중복된 좋아요는 불가능
- 최근 좋아요 순서도 추적해야 할 수 있음

**단순 접근**: Set으로 사용자 ID 저장
```
like:product:1001 = { 101, 102, 103, 105 } (사용자 ID들)
```

**개선 접근**: Sorted Set으로 시간 정보도 함께 저장
```
like:product:1001 = { (user_id: score) }
  101: 1700000000
  102: 1700000010
  103: 1700000020
```

왜 Sorted Set을 선택했을까?

나중에 **"최근 1시간 동안 좋아요한 사용자들"** 같은 비즈니스 요구사항이 생길 수 있기 때문입니다.
Sorted Set을 사용하면 score 범위로 쉽게 필터링할 수 있습니다.

최종적으로 아래와 같은 키구조를 생각했습니다.
```
like:product:1001(상품 ID) = { 101, 102, 103, 105 } (사용자 ID), score 순 정렬
```

그리고 Redis를 통해 아래와 같이 개선할 수 있습니다.
```java
@Transactional
      public void like(ProductLikeCommand command) {
          User user = userRepository.getByIdentifier(new UserIdentifier(command.getUserIdentifier()));
          Product product = productRepository.getById(new ProductId(command.getProductId()));

          long timestamp = System.currentTimeMillis();
          redisTemplate.opsForZSet().add(
              "like:product:" + product.getId().value(),
              user.getId().value(),
              timestamp
          );
      }
```

**무엇이 바뀌었을까?**

기존 코드에서는:
- 좋아요 저장 (DB 쓰기)
- 상품의 좋아요 수 증가 (DB 업데이트)

변경된 코드에서는:
- 사용자와 상품 조회만 수행
- **Redis에 즉시 저장하고 응답 반환**

데이터베이스 쓰기가 사라졌습니다.
생각하기에 겨우 쓰기 하나가 사라졌을 뿐이잖아? 라고 생각할 수 있지만 좋아요의 빈번한 요청 횟수와 데이터베이스의 읽기보다 쓰기에 대한 비용이 크다라는 점을 생각하면
결과적으로 **응답 속도가 비약적으로 빨라지고, 데이터베이스 부하가 크게 감소**합니다.

# 그래서?
---

**캐싱은 성능을 빠르게 하는 기술이 아니라, 데이터 특성을 파악한 선택의 문제입니다.**

제가 Cache Aside 테스트를 진행할 때 한 가지 중요한 가정이 있었습니다.
바로 **자주 조회되는 상품이 1000개 정도로 특정된다는 점**이었습니다.

다시 생각해보니 만약 이 가정이 깨진다면 어떻게 될까요?

예를 들어, 상품 데이터가 100만 건이 있고, 사용자들이 조회하는 상품이 랜덤하게 분산되어 있다면 어떨까요?

그렇다면 캐시 히트율은 급격히 낮아질 것입니다.

**캐시에 저장되는 데이터는 1000개인데, 조회되는 상품은 매번 다른 100만 개의 상품 중에서 선택되는 상황**이 되는 거죠.

이런 상황에서는 어떤 일이 발생할까요?

1. **캐시 미스가 대부분**: 대부분의 요청이 캐시에서 찾지 못하고 데이터베이스로 직접 접근
2. **캐시 저장의 오버헤드**: 캐시에 저장은 되지만 한 번 또는 두 번 조회되고 다시 요청되지 않음
3. **메모리 낭비**: 캐시 메모리를 차지하지만 실제로는 도움이 되지 않는 데이터들로 가득
4. **더 느린 응답**: 캐시를 조회하는 시간 + 미스 → 데이터베이스 조회라는 불필요한 오버헤드 발생

결국 **캐시를 구현하기 전에 우리가 먼저 해야 할 일은 데이터를 분석하는 것**입니다.

- **조회 패턴**: 정말로 특정된 데이터들이 자주 조회될까?
- **데이터 규모**: 전체 데이터 중 자주 조회되는 데이터는 몇 %일까?
- **캐시 공간**: 이 정도 규모의 데이터를 캐시에 보관하는 것이 실제로 가치 있을까?

제 테스트가 성공한 이유는 우연이 아니라 **의도적으로 자주 조회되는 1000개의 상품으로 한정했기 때문**입니다.

만약 실무에서 캐시를 도입한다면, 단순히 "조회가 많으니까 캐시 쓰자"라기 보다는

**"이 데이터는 정말 반복적으로 조회될까? 그렇다면 몇 개 정도일까? 캐시 히트율은 실제로 얼마나 될까?"**

이런 질문들에 답하고 난 다음에 도입하는 것이 중요합니다.

캐시는 결국 **비즈니스를 파악하고 데이터 특성에 맞게 사용할 때만 진가를 발휘하는 도구**라는 걸 느꼈습니다.
